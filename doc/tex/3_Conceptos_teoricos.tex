\capitulo{3}{Conceptos teóricos}

\section{Introducción}

Para comprender adecuadamente el proceso de compilación y las decisiones de diseño tomadas en este proyecto, es necesario introducir una serie de conceptos teóricos relacionados con la construcción de compiladores. Dado que los miembros del tribunal no tienen por qué estar familiarizados con la implementación interna de estos sistemas, en este capítulo se describen de forma general las distintas fases que componen un compilador moderno, así como las infraestructuras y técnicas empleadas habitualmente en su desarrollo.

El objetivo de esta sección no es presentar un glosario de definiciones aisladas, sino ofrecer una visión global del compilador como sistema, explicando cómo fluye la información entre las distintas etapas y cómo estas colaboran para transformar un programa escrito en un lenguaje de alto nivel en código ejecutable.

A lo largo del capítulo se describen las fases del proceso de compilación, el uso de representaciones intermedias y el papel de la infraestructura LLVM en el proyecto. En el capítulo 5 se presentan ejemplos concretos de este proceso, ilustrados mediante fragmentos de código del lenguaje desarrollado y las estructuras internas generadas durante la compilación.

\section{El concepto de compilar}
Un compilador es, en esencia, un traductor que permite a los programadores escribir en un lenguaje fácil de comprender por humanos y transformarlo a un lenguaje que pueda entender un ordenador. En la mayoría de compiladores modernos se añaden capas adicionales que permiten validar la corrección del programa y ofrecen la capacidad de optimizar el programa original, de forma que el resultado sea más eficiente.

Una distinción que merece la pena realizar es la diferencia entre compilar e interpretar como formas de hacer llegar a lenguaje máquina el código escrito en un lenguaje de alto nivel. Mientras que en la compilación la traducción del programa se realiza de forma previa a su ejecución, generando un código ejecutable independiente, en la interpretación el código se analiza y ejecuta de manera progresiva en tiempo de ejecución, lo que implica diferencias significativas tanto en el rendimiento como en el modelo de ejecución y control del programa.

\section{El proceso de compilación}

Un compilador es un sistema software cuya función principal es traducir un programa escrito en un lenguaje fuente a una forma equivalente que pueda ser ejecutada por un computador. Para facilitar su diseño, mantenimiento y extensión, la mayoría de compiladores modernos se estructuran como una secuencia de \textbf{fases} bien definidas, donde cada una cumple una responsabilidad concreta.

\subsection{Análisis léxico}

La primera etapa del proceso de compilación es el análisis léxico. En esta fase, el código fuente se procesa como una secuencia de caracteres que se agrupan en unidades significativas llamadas \emph{tókenes} o \emph{lexemas}. Cada token representa elementos básicos del lenguaje, como identificadores, palabras clave, literales u operadores.

El resultado del análisis léxico es una secuencia estructurada de tókenes que será utilizada por la fase de análisis sintáctico. Separar esta fase del resto permite simplificar el diseño del compilador y detectar errores léxicos de forma temprana.

\subsection{Análisis sintáctico}

A partir de la secuencia de tókenes generada por el análisis léxico, el análisis sintáctico se encarga de verificar que el programa cumple las reglas gramaticales del lenguaje. Para ello, los tókenes se agrupan siguiendo una gramática formal, produciendo una representación jerárquica del programa.

\subsection{Construcción del AST}

El Árbol de sintaxis abstracta o \emph{Abstract Syntax Tree} (AST), es una estructura de datos arbórea donde cada nodo representa un lexema, además, almacena información importante sobre este contexto sintáctico, eliminando detalles sintácticos innecesarios y facilitando su posterior análisis y transformación. El resultado final de este proceso representa la estructura lógica completa del programa, en el capítulo 5 se puede encontrar un ejemplo visual~\ref{capitulo5:AST} de un AST.

\subsection{Análisis semántico}

Una vez construido el AST, el compilador realiza el análisis semántico, cuya función es comprobar que el programa tiene sentido desde el punto de vista del lenguaje, más allá de su corrección sintáctica. En esta fase se verifican aspectos como el uso correcto de tipos, la declaración previa de identificadores o la coherencia de las expresiones.

Durante el análisis semántico se construye y mantiene la \textbf{tabla de símbolos}, una estructura de datos que asocia cada identificador del programa con información relevante como su tipo, categoría y ámbito de validez. Esta información será esencial en las fases posteriores de generación de código.

\subsubsection{Tipado}
El «tipado» en un lenguaje de programación se refiere a los tipos de datos soportados por el lenguaje. Los lenguajes se diferencian entre lenguajes de tipado dinámico y de tipado estático, los primeros permiten mayor libertad con respecto al uso de tipos, implementando un sistema de resolución de tipos en tiempo de ejecución, mientras que los segundos requieren conocer el uso de tipos en tiempo de compilación.

Para este proyecto se ha utilizado un sistema de tipos estático, apostando por la seguridad que ofrece esta arquitectura y evitando el gran tiempo que consume la creación de un sistema de tipos dinámico y seguro.

\subsubsection{Alcance o \eng{scope}}
En el ámbito de los compiladores los alcances se refieren a la posibilidad de acceder a un dato o hacer uso de una función desde un bloque de código concreto. Por ejemplo, si una variable es declarada dentro del bloque de código de una función, esta misma variable no puede ser utilizada fuera de dicho bloque de código.

El control de los alcances es fundamental para que la lógica del lenguaje sea correcta, el correcto uso de los alcances debe ser registrado por una estructura de datos, normalmente una tabla de símbolos. La fase responsable de orquestar este sistema es la fase de análisis semántico, sin embargo, los datos de alcance son utilizados durante todas las fases posteriores al análisis semántico.

\subsubsection{\eng{Shadowing} u ocultación}
La ocultación de identificador es una técnica de control de alcances que permite redefinir identificadores en diferentes \eng{scopes}, utilizando los alcances como única medida de control de acceso para identificadores con el mismo nombre.


\subsection{Generación de código intermedio}

Tras validar el programa, el compilador transforma el AST en una representación intermedia (IR). Esta forma intermedia actúa como puente entre el lenguaje fuente y el código máquina, permitiendo aplicar optimizaciones y desacoplar el las fases de análisis de la generación de código máquina en el compilador.

\subsubsection{LLVM IR}
En este proyecto se utiliza LLVM IR~\cite{llvm-ir-quick-reference} como representación intermedia, en el capítulo 5~\ref{capitulo5:LLVMIR:ejemplo} se pueden apreciar ejemplos concretos de programas y su IR. El uso de este IR junto con otros módulos de LLVM facilita tanto la aplicación de optimizaciones automáticas como la generación de código para distintas arquitecturas. 

\subsection{Optimización}

La fase de optimización tiene como objetivo mejorar el código generado sin alterar su comportamiento observable. Estas mejoras pueden centrarse en reducir el número de instrucciones, eliminar código innecesario o mejorar el uso de recursos.

Gracias a la infraestructura LLVM, este proyecto puede beneficiarse de un amplio conjunto de optimizaciones ya implementadas, como la propagación de constantes, la eliminación de código muerto o la simplificación de expresiones. En el capítulo 5~\ref{capitulo5:optimizaciones} se muestran ejemplos concretos de estas optimizaciones aplicadas al código generado.

\subsection{Generación de código final y \eng{runtime}}

La última fase del proceso consiste en transformar la representación intermedia optimizada en código máquina ejecutable. Para ello, LLVM se encarga de generar código específico para la arquitectura destino.

El código generado se apoya en un \eng{runtime}, encargado de proporcionar funcionalidades de soporte necesarias para la ejecución del programa, como la inicialización del entorno, la gestión de eventos o la interacción con bibliotecas externas.

\section{Infraestructura LLVM y modelo de compilación}

LLVM es una infraestructura de compilación moderna basada en un enfoque modular y por fases. A diferencia de compiladores monolíticos como GCC, donde las distintas etapas están fuertemente acopladas, LLVM permite separar la responsabilidad de las primeras fases de análisis de la representación y la generación de código ejecutable.  

Este enfoque permite reutilizar componentes, aplicar optimizaciones independientes del lenguaje fuente y generar código ejecutable independiente de la arquitectura \eng{host}. Estas características han sido determinantes para la elección de LLVM como un elemento central del desarrollo del compilador en este proyecto.
